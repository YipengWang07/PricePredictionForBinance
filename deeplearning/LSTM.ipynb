{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastparquet\n",
        "!pip install pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf16yjRgxx8d",
        "outputId": "b7101788-3529-4e61-b5ec-7fba5730d317"
      },
      "id": "Tf16yjRgxx8d",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastparquet in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from fastparquet) (2022.2.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.3.5)\n",
            "Requirement already satisfied: cramjam>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from fastparquet) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->fastparquet) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->fastparquet) (1.15.0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "be3320a7",
      "metadata": {
        "id": "be3320a7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import sklearn\n",
        "import sklearn.preprocessing\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "64d845b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "64d845b8",
        "outputId": "3231374c-30ef-40f8-ecb7-d156d35270da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2347102 entries, 2017-08-17 04:00:00 to 2022-02-07 23:59:00\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Dtype  \n",
            "---  ------  -----  \n",
            " 0   open    float32\n",
            " 1   high    float32\n",
            " 2   low     float32\n",
            " 3   close   float32\n",
            "dtypes: float32(4)\n",
            "memory usage: 53.7 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5b8d103f-429e-44c9-bc73-0e640f4441c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>open_time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-08-17 04:00:00</th>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-17 04:01:00</th>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-17 04:02:00</th>\n",
              "      <td>4280.560059</td>\n",
              "      <td>4280.560059</td>\n",
              "      <td>4280.560059</td>\n",
              "      <td>4280.560059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-17 04:03:00</th>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-08-17 04:04:00</th>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "      <td>4261.479980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b8d103f-429e-44c9-bc73-0e640f4441c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b8d103f-429e-44c9-bc73-0e640f4441c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b8d103f-429e-44c9-bc73-0e640f4441c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                            open         high          low        close\n",
              "open_time                                                              \n",
              "2017-08-17 04:00:00  4261.479980  4261.479980  4261.479980  4261.479980\n",
              "2017-08-17 04:01:00  4261.479980  4261.479980  4261.479980  4261.479980\n",
              "2017-08-17 04:02:00  4280.560059  4280.560059  4280.560059  4280.560059\n",
              "2017-08-17 04:03:00  4261.479980  4261.479980  4261.479980  4261.479980\n",
              "2017-08-17 04:04:00  4261.479980  4261.479980  4261.479980  4261.479980"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df = pd.read_parquet('./BTC-USDT.parquet')\n",
        "\n",
        "df.drop(['volume', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume'],1,inplace=True)\n",
        "df.info()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4360712e",
      "metadata": {
        "id": "4360712e"
      },
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "    opens = df.open.values.reshape(-1,1)\n",
        "    lows = df.low.values.reshape(-1,1)\n",
        "    highs = df.high.values.reshape(-1,1)\n",
        "    closes = df['close'].values.reshape(-1,1)\n",
        "    scale = min_max_scaler.fit(opens + highs + lows + closes)\n",
        "    df['open'] = scale.transform(opens)\n",
        "    df['high'] = scale.transform(highs)\n",
        "    df['low'] = scale.transform(lows)\n",
        "    df['close'] = scale.transform(closes)\n",
        "    return df\n",
        "\n",
        "def load_data(stock, seq_len):\n",
        "    data_raw = stock.values # convert to numpy array\n",
        "    data = []\n",
        "    \n",
        "    # create all possible sequences of length seq_len\n",
        "    for index in range(len(data_raw) - seq_len): \n",
        "        data.append(data_raw[index: index + seq_len])\n",
        "    \n",
        "    data = np.array(data); \n",
        "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]))\n",
        "    train_set_size = data.shape[0] - test_set_size\n",
        "    \n",
        "    x_train = data[:train_set_size,:-1,:]\n",
        "    y_train = data[:train_set_size,-1,:]\n",
        "    \n",
        "    x_test = data[train_set_size:,:-1,:]\n",
        "    y_test = data[train_set_size:,-1,:]\n",
        "    \n",
        "    return [x_train, y_train, x_test, y_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "87bde8b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87bde8b2",
        "outputId": "5e269dda-e8d6-4324-9ff0-325bb8dc371f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape =  (2112374, 19, 4)\n",
            "y_train.shape =  (2112374, 4)\n",
            "x_test.shape =  (234708, 19, 4)\n",
            "y_test.shape =  (234708, 4)\n"
          ]
        }
      ],
      "source": [
        "valid_set_size_percentage = 10 \n",
        "test_set_size_percentage = 10 \n",
        "# normalize stock\n",
        "df_stock_norm = df.copy()\n",
        "df_stock_norm = normalize_data(df_stock_norm)\n",
        "\n",
        "# create train, test data\n",
        "seq_len = 20 # choose sequence length\n",
        "x_train, y_train, x_test, y_test = load_data(df_stock_norm, seq_len)\n",
        "print('x_train.shape = ',x_train.shape)\n",
        "print('y_train.shape = ', y_train.shape)\n",
        "print('x_test.shape = ', x_test.shape)\n",
        "print('y_test.shape = ',y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "81db5ed0",
      "metadata": {
        "id": "81db5ed0"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=4, hidden_size=128, num_layers=1, bidirectional=False, batch_first=True, dropout = 0.2)\n",
        "        self.fn = nn.Linear(128, 4)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize, max_len, emb_dim = x.shape\n",
        "        output, (h, c) = self.lstm(x)\n",
        "        output = self.relu(output[:,-1,:])\n",
        "        output = self.fn(output)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a72da931",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a72da931",
        "outputId": "e7f04d1a-9b2a-4bf4-bcf8-3c2ae5fa1543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch count:1000, avg train loss:7.895523555878903e-05\n",
            "batch count:2000, avg train loss:4.832209505032381e-07\n",
            "batch count:3000, avg train loss:3.7643369036466365e-07\n",
            "batch count:4000, avg train loss:3.028107323945761e-07\n",
            "batch count:5000, avg train loss:2.689605074106538e-07\n",
            "batch count:6000, avg train loss:2.476487094371649e-07\n",
            "batch count:7000, avg train loss:2.1073113575642567e-07\n",
            "batch count:8000, avg train loss:1.8187151296000793e-07\n",
            "batch count:9000, avg train loss:1.6813274816840362e-07\n",
            "batch count:10000, avg train loss:1.5091208274586876e-07\n",
            "batch count:11000, avg train loss:1.545325941272324e-07\n",
            "batch count:12000, avg train loss:1.2945435915412418e-07\n",
            "batch count:13000, avg train loss:9.927452048863473e-08\n",
            "batch count:14000, avg train loss:1.1354343699299108e-07\n",
            "batch count:15000, avg train loss:1.1212307348973382e-07\n",
            "batch count:16000, avg train loss:1.2857228527263232e-07\n",
            "batch count:17000, avg train loss:6.218717319184108e-08\n",
            "batch count:18000, avg train loss:7.93353482375636e-08\n",
            "batch count:19000, avg train loss:8.71701842712902e-08\n",
            "batch count:20000, avg train loss:6.86487684693482e-08\n",
            "batch count:21000, avg train loss:7.603010803247656e-08\n",
            "batch count:22000, avg train loss:6.308812798883068e-08\n",
            "batch count:23000, avg train loss:6.662444802962852e-08\n",
            "batch count:24000, avg train loss:7.251491027027157e-08\n",
            "batch count:25000, avg train loss:5.986993291617893e-08\n",
            "batch count:26000, avg train loss:6.122214929860093e-08\n",
            "batch count:27000, avg train loss:5.648192573026733e-08\n",
            "batch count:28000, avg train loss:5.501347752057128e-08\n",
            "batch count:29000, avg train loss:6.308800579679641e-08\n",
            "batch count:30000, avg train loss:5.2609213297305504e-08\n",
            "batch count:31000, avg train loss:4.907033234591296e-08\n",
            "batch count:32000, avg train loss:5.664149383610706e-08\n",
            "batch count:33000, avg train loss:4.5689560222772484e-08\n",
            "batch count:34000, avg train loss:5.59901794208173e-08\n",
            "batch count:35000, avg train loss:4.498469788938309e-08\n",
            "batch count:36000, avg train loss:4.352463506629434e-08\n",
            "batch count:37000, avg train loss:5.060237685361457e-08\n",
            "batch count:38000, avg train loss:5.393408462150973e-08\n",
            "batch count:39000, avg train loss:3.915265231668741e-08\n",
            "batch count:40000, avg train loss:4.1618320918868076e-08\n",
            "batch count:41000, avg train loss:4.721951610120456e-08\n",
            "batch count:42000, avg train loss:4.60026407194114e-08\n",
            "batch count:43000, avg train loss:3.948428190270192e-08\n",
            "batch count:44000, avg train loss:3.678975715981636e-08\n",
            "batch count:45000, avg train loss:4.180208405735186e-08\n",
            "batch count:46000, avg train loss:3.8141742965347445e-08\n",
            "batch count:47000, avg train loss:4.2854860796026626e-08\n",
            "batch count:48000, avg train loss:3.940732690854709e-08\n",
            "batch count:49000, avg train loss:3.844216124937461e-08\n"
          ]
        }
      ],
      "source": [
        "index_in_epoch = 0;\n",
        "perm_array  = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(perm_array)\n",
        "\n",
        "# function to get the next batch\n",
        "def get_next_batch(batch_size):\n",
        "    global index_in_epoch, x_train, perm_array   \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size\n",
        "    \n",
        "    if index_in_epoch > x_train.shape[0]:\n",
        "        np.random.shuffle(perm_array) # shuffle permutation array\n",
        "        start = 0 # start next epoch\n",
        "        index_in_epoch = batch_size\n",
        "        \n",
        "    end = index_in_epoch\n",
        "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "n_epochs = 3\n",
        "train_set_size = x_train.shape[0]\n",
        "test_set_size = x_test.shape[0]\n",
        "\n",
        "model = Model().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "model.train()\n",
        "cnt = 0\n",
        "avg_loss = 0.\n",
        "for epoch in range(int(n_epochs * train_set_size/ batch_size)):\n",
        "    optimizer.zero_grad()\n",
        "    x_batch, y_batch = get_next_batch(batch_size)\n",
        "    x_batch = torch.tensor(x_batch).to(device)\n",
        "    y_batch = torch.tensor(y_batch)\n",
        "    y_pred = model(x_batch).cpu()\n",
        "    loss = criterion(y_pred, y_batch)\n",
        "    avg_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    cnt += 1\n",
        "    if cnt % 1000 == 0:\n",
        "        print(\"batch count:{}, avg train loss:{}\".format(cnt, avg_loss / 1000))\n",
        "        avg_loss = 0.\n",
        "\n",
        "torch.save(model.state_dict(), \"./parameters.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model().to(device)\n",
        "model.load_state_dict(torch.load(\"./parameters.pt\"))\n",
        "model.eval()\n",
        "criterion = torch.nn.MSELoss(reduction=\"sum\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hAYbcZe5uLM",
        "outputId": "93bf8597-93d3-4202-feef-7885b67fa809"
      },
      "id": "2hAYbcZe5uLM",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 0.\n",
        "batch_size = 256\n",
        "num = math.ceil(test_set_size / batch_size)\n",
        "start = 0\n",
        "with torch.no_grad():\n",
        "  for cnt in range(num):\n",
        "    x_batch = x_test[start:min(start+batch_size, test_set_size),:,:]\n",
        "    y_batch = y_test[start:min(start+batch_size, test_set_size),:]\n",
        "    y_pred = model(torch.tensor(x_batch).to(device)).cpu()\n",
        "    loss += criterion(y_pred, torch.tensor(y_batch))\n",
        "    start += batch_size\n",
        "    #print(y_batch[:5,:])\n",
        "    #print(y_pred[:5,:].cpu().numpy())\n",
        "\n",
        "print(\"test mse loss:{}\".format(loss / test_set_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kunZuGCz6Ike",
        "outputId": "db9e9ef5-911e-4cc1-d990-fcc68f63e0bc"
      },
      "id": "kunZuGCz6Ike",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test mse loss:2.3527253745214693e-07\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "CS5245_PJ_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}